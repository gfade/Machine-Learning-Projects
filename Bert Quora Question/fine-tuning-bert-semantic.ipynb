{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport torch\nimport seaborn as sns \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch.nn.functional as F\nfrom sklearn.linear_model import LinearcRegression\nfrom transformers import pipeline, AutoTokenizer # for HuggingFace Transformers\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-27T18:34:48.386204Z","iopub.execute_input":"2021-09-27T18:34:48.386531Z","iopub.status.idle":"2021-09-27T18:34:48.401496Z","shell.execute_reply.started":"2021-09-27T18:34:48.386501Z","shell.execute_reply":"2021-09-27T18:34:48.400599Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"/kaggle/input/tester/df.pkl\n/kaggle/input/tester/test.pkl\n/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\nlogreg = LinearRegression()","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:34:48.403538Z","iopub.execute_input":"2021-09-27T18:34:48.403904Z","iopub.status.idle":"2021-09-27T18:34:49.661742Z","shell.execute_reply.started":"2021-09-27T18:34:48.403862Z","shell.execute_reply":"2021-09-27T18:34:49.660752Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"df = pd.read_pickle(r'../input/tester/df.pkl')\ny_lab = df['is_duplicate']\nX_sim = df.apply(lambda x:np.dot((tokenizer.encode(str(x.question1),padding=\"max_length\")),(tokenizer.encode(str(x.question2),padding=\"max_length\"))),axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:34:49.686086Z","iopub.execute_input":"2021-09-27T18:34:49.686429Z","iopub.status.idle":"2021-09-27T18:42:48.961268Z","shell.execute_reply.started":"2021-09-27T18:34:49.686400Z","shell.execute_reply":"2021-09-27T18:42:48.960188Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"y_label = df['is_duplicate']\nlogreg.fit(X_sim.values.reshape(-1, 1),y_label)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:43:28.448873Z","iopub.execute_input":"2021-09-27T18:43:28.449147Z","iopub.status.idle":"2021-09-27T18:43:29.294085Z","shell.execute_reply.started":"2021-09-27T18:43:28.449118Z","shell.execute_reply":"2021-09-27T18:43:29.293289Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"LogisticRegression()"},"metadata":{}}]},{"cell_type":"code","source":"#dot_product =   [np.dot(tokenizer.encode(row[3]),tokenizer.encode(row[4])) for row in df]\ntest_df = pd.read_pickle(r'../input/tester/test.pkl')\ntest_id = test_df['test_id']\ntest_sim = test_df.apply(lambda x:np.dot((tokenizer.encode(str(x.question1),padding=\"max_length\")),(tokenizer.encode(str(x.question2),padding=\"max_length\"))),axis=1)\nis_duplicate = logreg.predict(test_sim.values.reshape(-1,1))\nreturn_dic = pd.DataFrame()\nreturn_dic['test_id']=test_id\nreturn_dic['is_duplicate']=is_duplicate\nreturn_df = pd.DataFrame(return_dic)\nreturn_df.to_csv('answer2.csv',index = False,header=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-27T18:43:29.295656Z","iopub.execute_input":"2021-09-27T18:43:29.296173Z","iopub.status.idle":"2021-09-27T19:30:00.063896Z","shell.execute_reply.started":"2021-09-27T18:43:29.296129Z","shell.execute_reply":"2021-09-27T19:30:00.062836Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"2345796\n2345796\n","output_type":"stream"}]}]}