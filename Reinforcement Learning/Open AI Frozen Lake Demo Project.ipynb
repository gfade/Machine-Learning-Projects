{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gym \nfrom gym import envs\nfrom IPython.display import Image\nimport os\nfrom IPython import display\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-12-17T02:55:18.528546Z","iopub.execute_input":"2021-12-17T02:55:18.529195Z","iopub.status.idle":"2021-12-17T02:55:18.583491Z","shell.execute_reply.started":"2021-12-17T02:55:18.529131Z","shell.execute_reply":"2021-12-17T02:55:18.582119Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nenv = gym.make('FrozenLake8x8-v0')\nenv.action_space","metadata":{"execution":{"iopub.status.busy":"2021-12-17T02:55:18.586832Z","iopub.execute_input":"2021-12-17T02:55:18.587309Z","iopub.status.idle":"2021-12-17T02:55:19.574742Z","shell.execute_reply.started":"2021-12-17T02:55:18.587228Z","shell.execute_reply":"2021-12-17T02:55:19.573045Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"env.reset() \nenv.render() \n\naction = env.action_space.sample() \nenv.step(action) ","metadata":{"execution":{"iopub.status.busy":"2021-12-17T02:55:19.576356Z","iopub.execute_input":"2021-12-17T02:55:19.576667Z","iopub.status.idle":"2021-12-17T02:55:19.587268Z","shell.execute_reply.started":"2021-12-17T02:55:19.576621Z","shell.execute_reply":"2021-12-17T02:55:19.586330Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"observation = env.reset() \n\nfor t in range(20):\n    env.render()\n    action = env.action_space.sample()\n    observation, reward, done, info = env.step(action) \n    print(observation, reward, done) \n    if done: \n        print(\"Episode finished after {} timesteps\".format(t+1)) # Print the timesteps\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-17T02:55:19.588746Z","iopub.execute_input":"2021-12-17T02:55:19.589069Z","iopub.status.idle":"2021-12-17T02:55:19.607113Z","shell.execute_reply.started":"2021-12-17T02:55:19.589027Z","shell.execute_reply":"2021-12-17T02:55:19.605077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\n\nobservation = env.reset() \nfor t in range(20):\n    env.render() \n    action = env.action_space.sample()\n    observation, reward, done, info = env.step(action) \n    print(observation, reward, done)\n    display.clear_output(wait=True) \n    time.sleep(1) \n    print(\"step:\", t)\n    if done:\n        print(\"Done after {} timesteps\".format(t+1))\n        break","metadata":{"execution":{"iopub.status.busy":"2021-12-17T02:55:19.609393Z","iopub.execute_input":"2021-12-17T02:55:19.609882Z","iopub.status.idle":"2021-12-17T02:55:30.665696Z","shell.execute_reply.started":"2021-12-17T02:55:19.609806Z","shell.execute_reply":"2021-12-17T02:55:30.664698Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}